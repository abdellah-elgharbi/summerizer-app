import streamlit as st
from transformers import pipeline
import time
import torch
import PyPDF2
from io import BytesIO

# Configuration de la page
st.set_page_config(
    page_title="Article Summarizer Bot",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ© pour le chat
st.markdown("""
    <style>
    .chat-container {
        display: flex;
        flex-direction: column;
        gap: 10px;
        padding: 10px;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 12px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 4px solid #2196F3;
    }
    .bot-message {
        background-color: #f5f5f5;
        padding: 12px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 4px solid #4CAF50;
    }
    .bot-message strong {
        color: #2e7d32;
    }
    .input-area {
        position: fixed;
        bottom: 0;
        width: 100%;
        background-color: white;
        padding: 15px;
        box-shadow: 0 -2px 10px rgba(0,0,0,0.1);
    }
    .stFileUploader {
        margin-bottom: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# Titre
col1, col2 = st.columns([0.8, 0.2])
with col1:
    st.title("ğŸ¤– Article Summarizer Bot")
with col2:
    st.write("")
    if st.button("ğŸ”„ Nouveau Chat", key="reset_btn"):
        st.session_state.messages = []
        st.rerun()

st.markdown("Envoyez-moi vos articles ou importez un PDF pour les rÃ©sumer automatiquement!")
st.markdown("---")

# Sidebar - ParamÃ¨tres
st.sidebar.header("âš™ï¸ ParamÃ¨tres")
model_choice = st.sidebar.selectbox(
    "ModÃ¨le:",
    [
        "Votre modÃ¨le personnalisÃ©",
        "distilbart-cnn-6-6",
        "facebook/bart-large-cnn"
    ],
    index=0
)

device = "cuda" if torch.cuda.is_available() else "cpu"
st.sidebar.info(f"ğŸ“± Appareil: {device.upper()}")
st.sidebar.info("â„¹ï¸ Utilisation des paramÃ¨tres par dÃ©faut du modÃ¨le")

# Initialiser l'historique des messages
if "messages" not in st.session_state:
    st.session_state.messages = []

# âš™ï¸ CONFIGURATION - MODIFIEZ LE CHEMIN ICI âš™ï¸
CUSTOM_MODEL_PATH = "C:/Users/abdel/Downloads/my_model/content/my_model"  # ğŸ‘ˆ REMPLACEZ PAR LE CHEMIN DE VOTRE MODÃˆLE

# Fonction pour extraire le texte d'un PDF
def extract_text_from_pdf(pdf_file):
    try:
        pdf_reader = PyPDF2.PdfReader(BytesIO(pdf_file.read()))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip(), None
    except Exception as e:
        return None, f"Erreur lors de la lecture du PDF: {str(e)}"

# Charger le modÃ¨le
@st.cache_resource
def load_summarizer(model_name):
    try:
        if model_name == "Votre modÃ¨le personnalisÃ©":
            model_path = CUSTOM_MODEL_PATH
        else:
            model_path = model_name
        
        summarizer = pipeline(
            "summarization",
            model=model_path,
            device=0 if device == "cuda" else -1
        )
        return summarizer, None
    except Exception as e:
        return None, f"Erreur: {str(e)}"

summarizer, error = load_summarizer(model_choice)

if error:
    st.sidebar.error(f"âŒ {error}")
else:
    st.sidebar.success(f"âœ… {model_choice} chargÃ©!")

# Zone d'upload de fichier PDF
st.markdown("### ğŸ“„ Importer un PDF")
uploaded_file = st.file_uploader(
    "Choisissez un fichier PDF",
    type=['pdf'],
    help="TÃ©lÃ©chargez un PDF pour en extraire et rÃ©sumer le contenu",
    key="pdf_uploader"
)

# Traiter le PDF uploadÃ©
if uploaded_file is not None:
    with st.spinner("ğŸ“– Lecture du PDF..."):
        extracted_text, pdf_error = extract_text_from_pdf(uploaded_file)
        
        if pdf_error:
            st.error(pdf_error)
        elif extracted_text:
            # Ajouter le message utilisateur (extrait du PDF)
            preview_text = extracted_text[:500] + "..." if len(extracted_text) > 500 else extracted_text
            
            st.session_state.messages.append({
                "role": "user",
                "content": f"ğŸ“„ PDF: {uploaded_file.name}\n\n{extracted_text}"
            })
            
            # Afficher un aperÃ§u
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.write(f"**ğŸ“„ PDF importÃ©:** {uploaded_file.name}")
                with st.expander("ğŸ“– AperÃ§u du contenu"):
                    st.write(preview_text)
            
            # GÃ©nÃ©rer le rÃ©sumÃ©
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                word_count = len(extracted_text.split())
                
                if word_count < 50:
                    bot_response = f"âš ï¸ Le contenu du PDF est trop court ({word_count} mots). Veuillez envoyer un document avec au moins 50 mots."
                elif summarizer is None:
                    bot_response = "âŒ Le modÃ¨le n'a pas pu Ãªtre chargÃ©."
                else:
                    try:
                        with st.spinner("â³ GÃ©nÃ©ration du rÃ©sumÃ©..."):
                            start = time.time()
                            
                            # Limiter la taille de l'input
                            text_to_summarize = extracted_text[:1024]
                            
                            # GÃ©nÃ©rer le rÃ©sumÃ©
                            summary_result = summarizer(
                                text_to_summarize,
                                do_sample=False
                            )
                            
                            elapsed = time.time() - start
                            summary_text = summary_result[0]['summary_text']
                            summary_words = len(summary_text.split())
                            compression = (1 - summary_words/word_count) * 100 if word_count > 0 else 0
                            
                            bot_response = f"""
**ğŸ“„ RÃ‰SUMÃ‰ GÃ‰NÃ‰RÃ‰:**

{summary_text}

---

**ğŸ“Š STATISTIQUES:**
- ğŸ“ Fichier: {uploaded_file.name}
- ğŸ“ Document: {word_count} mots
- âœ‚ï¸ RÃ©sumÃ©: {summary_words} mots  
- ğŸ“‰ Compression: {compression:.1f}%
- â±ï¸ Temps: {elapsed:.2f}s
- ğŸ§  ModÃ¨le: {model_choice}
"""
                            
                    except Exception as e:
                        bot_response = f"âŒ Erreur: {str(e)}\n\nEssayez avec un document plus court ou changez de modÃ¨le."
                
                st.markdown(bot_response)
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": bot_response
                })
        else:
            st.warning("âš ï¸ Aucun texte n'a pu Ãªtre extrait du PDF.")

st.markdown("---")

# Afficher les messages du chat
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        if message["role"] == "user":
            with st.chat_message("user", avatar="ğŸ‘¤"):
                content = message["content"]
                if content.startswith("ğŸ“„ PDF:"):
                    # Afficher uniquement le nom du fichier pour les PDF
                    file_name = content.split("\n")[0]
                    st.write(file_name)
                else:
                    st.write(content[:200] + "..." if len(content) > 200 else content)
        else:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown(message["content"])

# Zone de saisie
st.markdown("<br>" * 2, unsafe_allow_html=True)
st.markdown("### âœï¸ Ou saisissez votre texte directement")

# Input utilisateur
user_input = st.chat_input(
    "ğŸ“ Collez votre article ici...",
    key="user_input"
)

# Traiter l'entrÃ©e utilisateur
if user_input:
    st.session_state.messages.append({
        "role": "user",
        "content": user_input
    })
    
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.write(user_input[:200] + "..." if len(user_input) > 200 else user_input)
    
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        word_count = len(user_input.split())
        
        if word_count < 50:
            bot_response = f"âš ï¸ L'article est trop court ({word_count} mots). Veuillez envoyer un article avec au moins 50 mots."
        elif summarizer is None:
            bot_response = "âŒ Le modÃ¨le n'a pas pu Ãªtre chargÃ©."
        else:
            try:
                with st.spinner("â³ GÃ©nÃ©ration du rÃ©sumÃ©..."):
                    start = time.time()
                    text_to_summarize = user_input[:1024]
                    
                    summary_result = summarizer(
                        text_to_summarize,
                        do_sample=False
                    )
                    
                    elapsed = time.time() - start
                    summary_text = summary_result[0]['summary_text']
                    summary_words = len(summary_text.split())
                    compression = (1 - summary_words/word_count) * 100 if word_count > 0 else 0
                    
                    bot_response = f"""
**ğŸ“„ RÃ‰SUMÃ‰ GÃ‰NÃ‰RÃ‰:**

{summary_text}

---

**ğŸ“Š STATISTIQUES:**
- ğŸ“ Article: {word_count} mots
- âœ‚ï¸ RÃ©sumÃ©: {summary_words} mots  
- ğŸ“‰ Compression: {compression:.1f}%
- â±ï¸ Temps: {elapsed:.2f}s
- ğŸ§  ModÃ¨le: {model_choice}
"""
                    
            except Exception as e:
                bot_response = f"âŒ Erreur: {str(e)}\n\nEssayez avec un texte plus court ou changez de modÃ¨le."
        
        st.markdown(bot_response)
        
        st.session_state.messages.append({
            "role": "assistant",
            "content": bot_response
        })

# Pied de page
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 11px;'>
ğŸ¤– Article Summarizer Bot | Powered by DistilBart & Streamlit | Supporte PDF
</div>
""", unsafe_allow_html=True)